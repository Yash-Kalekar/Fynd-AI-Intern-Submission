{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "423ca9da-633a-4aa0-9aac-18386e01c745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8de7390-db4b-40d4-bc37-ff6a4fe062fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "CACHE_PATH = \"llm_cache.json\"\n",
    "\n",
    "LLM_CACHE = {}\n",
    "\n",
    "if os.path.exists(CACHE_PATH):\n",
    "    try:\n",
    "        with open(CACHE_PATH, \"r\") as f:\n",
    "            LLM_CACHE = json.load(f)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Cache file corrupted. Reinitializing cache.\")\n",
    "        LLM_CACHE = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f70efc0-1a18-4f6a-a2f9-5e43fea99b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"GEMINI_API_KEY not found in .env\")\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-flash-lite-latest\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8a7a20e-34ce-494a-8743-2d3b0fbfacad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A nice place to shop, but I wouldn't want to l...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The cheesy breadsticks were delicious.  Everyt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ok, so I have to share my morning experience. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two times a year, you can meander down Mill Av...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Older restrant but very good food</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  A nice place to shop, but I wouldn't want to l...      3\n",
       "1  The cheesy breadsticks were delicious.  Everyt...      1\n",
       "2  Ok, so I have to share my morning experience. ...      1\n",
       "3  Two times a year, you can meander down Mill Av...      4\n",
       "4                  Older restrant but very good food      4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/yelp.csv\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76dc082d-aceb-41a1-afa8-0327edb309fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'stars'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f97d754f-0ca0-4516-a859-03788b7b1171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I think everyone has said most everything that...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This Chipotle Rocks!  \\nToday, I express my jo...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The only reason 1 star can be given is the fla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I only ask for two things when I'm flying. To ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ok, they should be happy that I am understandi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  I think everyone has said most everything that...      5\n",
       "1  This Chipotle Rocks!  \\nToday, I express my jo...      5\n",
       "2  The only reason 1 star can be given is the fla...      1\n",
       "3  I only ask for two things when I'm flying. To ...      1\n",
       "4  Ok, they should be happy that I am understandi...      3"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLE_SIZE = 60\n",
    "df_sample = df.sample(SAMPLE_SIZE, random_state=42)\n",
    "\n",
    "df_sample = df_sample[['text', 'stars']].reset_index(drop=True)\n",
    "df_sample.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b8a052f-8c34-4224-a60e-de962db6c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def call_llm(prompt, cache_key):\n",
    "    if cache_key in LLM_CACHE:\n",
    "        return LLM_CACHE[cache_key]\n",
    "\n",
    "    response = model.generate_content(\n",
    "        prompt,\n",
    "        generation_config={\"temperature\": 0}\n",
    "    )\n",
    "\n",
    "    text = response.text\n",
    "\n",
    "    LLM_CACHE[cache_key] = text\n",
    "    with open(CACHE_PATH, \"w\") as f:\n",
    "        json.dump(LLM_CACHE, f, indent=2)\n",
    "\n",
    "    time.sleep(6.5)\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc87f38a-a8af-4ad2-a61d-be0c1c960370",
   "metadata": {},
   "source": [
    "## Prompt Version 1: Basic Classification\r\n",
    "\r\n",
    "This prompt directly asks the model to classify the review into a star rating.\r\n",
    "It has minimal constraints and no strong formatting enforcement.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a28c89f8-98e2-4a3f-8ef9-1b114d79acc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_v1_batch(reviews):\n",
    "    reviews_text = \"\\n\".join(\n",
    "        [f\"{i+1}. {r}\" for i, r in enumerate(reviews)]\n",
    "    )\n",
    "\n",
    "    return f\"\"\"\n",
    "Classify each Yelp review below into a star rating from 1 to 5.\n",
    "\n",
    "Reviews:\n",
    "{reviews_text}\n",
    "\n",
    "Return the output as a JSON array.\n",
    "Each element should contain:\n",
    "- predicted_stars\n",
    "- explanation\n",
    "\n",
    "Output only JSON.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c8e048-4d8f-4f1a-9b8d-da28ceddbb15",
   "metadata": {},
   "source": [
    "## Prompt Version 2: Explicit Constraints & Schema\r\n",
    "\r\n",
    "Changes:\r\n",
    "- Explicitly restrict star values to integers 1–5\r\n",
    "- Emphasize strict JSON output\r\n",
    "- Reduce verbosity\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6cb976e-df0c-426b-87e5-f1e0322ad91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_v2_batch(reviews):\n",
    "    reviews_text = \"\\n\".join(\n",
    "        [f\"{i+1}. {r}\" for i, r in enumerate(reviews)]\n",
    "    )\n",
    "\n",
    "    return f\"\"\"\n",
    "You are a sentiment analysis system.\n",
    "\n",
    "For EACH review below, predict a Yelp star rating (1–5).\n",
    "\n",
    "Rules:\n",
    "- Output MUST be valid JSON\n",
    "- Output MUST be an array\n",
    "- Order must match input order\n",
    "- Each item must contain:\n",
    "  - predicted_stars (integer 1–5)\n",
    "  - explanation (short)\n",
    "\n",
    "Reviews:\n",
    "{reviews_text}\n",
    "\n",
    "Output JSON ONLY in this format:\n",
    "[\n",
    "  {{\n",
    "    \"predicted_stars\": 5,\n",
    "    \"explanation\": \"reason\"\n",
    "  }}\n",
    "]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49638e0c-4101-4477-ab40-3dafdc5b41f0",
   "metadata": {},
   "source": [
    "## Prompt Version 3: Few-Shot Learning\r\n",
    "\r\n",
    "Changes:\r\n",
    "- Provide examples\r\n",
    "- Improve consistency and calibration\r\n",
    "- Reduce hallucination\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2f07e7d8-b7f4-4d6c-8566-98163d3a00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_v3_batch(reviews):\n",
    "    reviews_text = \"\\n\".join(\n",
    "        [f\"{i+1}. {r}\" for i, r in enumerate(reviews)]\n",
    "    )\n",
    "\n",
    "    return f\"\"\"\n",
    "You are an expert Yelp review classifier.\n",
    "\n",
    "Examples:\n",
    "Review: \"Amazing food and friendly staff.\"\n",
    "Rating: 5\n",
    "\n",
    "Review: \"The service was slow and the food was cold.\"\n",
    "Rating: 1\n",
    "\n",
    "Now classify EACH review below.\n",
    "\n",
    "Rules:\n",
    "- Ratings must be integers from 1 to 5\n",
    "- Output MUST be valid JSON\n",
    "- Output MUST be an array\n",
    "- Order MUST match input order\n",
    "- No text outside JSON\n",
    "\n",
    "Reviews:\n",
    "{reviews_text}\n",
    "\n",
    "Output JSON format:\n",
    "[\n",
    "  {{\n",
    "    \"predicted_stars\": 5,\n",
    "    \"explanation\": \"Short justification\"\n",
    "  }}\n",
    "]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f983419c-c3ee-4336-aa69-593bc5b30860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_reviews(reviews, batch_size=10):\n",
    "    for i in range(0, len(reviews), batch_size):\n",
    "        yield reviews[i:i + batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d34573ab-3b51-446b-bafb-0a43c80a5245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_response(response):\n",
    "    try:\n",
    "        data = json.loads(response)\n",
    "        stars = int(data[\"predicted_stars\"])\n",
    "        valid = 1 <= stars <= 5\n",
    "        return stars if valid else None, valid\n",
    "    except:\n",
    "        return None, False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79d4a188-d340-4c13-aad8-200d554094e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prompt_batch(prompt_fn, df, prompt_name, batch_size=10):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    valids = []\n",
    "\n",
    "    reviews = df[\"text\"].tolist()\n",
    "    actuals = df[\"stars\"].tolist()\n",
    "\n",
    "    for batch_idx, batch in enumerate(batch_reviews(reviews, batch_size)):\n",
    "        cache_key = f\"{prompt_name}_batch_{batch_idx}\"\n",
    "\n",
    "        output = call_llm(\n",
    "            prompt_fn(batch),\n",
    "            cache_key\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            results = json.loads(output)\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "        for i, item in enumerate(results):\n",
    "            global_index = batch_idx * batch_size + i\n",
    "            if global_index >= len(actuals):\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                star = int(item[\"predicted_stars\"])\n",
    "                valid = 1 <= star <= 5\n",
    "            except:\n",
    "                star, valid = None, False\n",
    "\n",
    "            if valid:\n",
    "                y_pred.append(star)\n",
    "                y_true.append(actuals[global_index])\n",
    "                valids.append(True)\n",
    "            else:\n",
    "                valids.append(False)\n",
    "\n",
    "    if len(y_pred) == 0:\n",
    "        accuracy = 0.0\n",
    "        json_validity = 0.0\n",
    "    else:\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        json_validity = sum(valids) / len(valids)\n",
    "\n",
    "    return accuracy, json_validity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2c17b31c-c294-4505-87c5-6a2646e541bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt Version</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>JSON Validity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt_V1_Batch</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prompt_V2_Batch</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prompt_V3_Batch</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prompt Version  Accuracy  JSON Validity\n",
       "0  Prompt_V1_Batch       0.0            0.0\n",
       "1  Prompt_V2_Batch       0.0            0.0\n",
       "2  Prompt_V3_Batch       0.8            1.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, fn in [\n",
    "    (\"Prompt_V1_Batch\", prompt_v1_batch),\n",
    "    (\"Prompt_V2_Batch\", prompt_v2_batch),\n",
    "    (\"Prompt_V3_Batch\", prompt_v3_batch),\n",
    "]:\n",
    "    acc, json_rate = evaluate_prompt_batch(\n",
    "        fn,\n",
    "        df_sample,\n",
    "        name,\n",
    "        batch_size=10\n",
    "    )\n",
    "    results.append([name, acc, json_rate])\n",
    "\n",
    "results_df = pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"Prompt Version\", \"Accuracy\", \"JSON Validity\"]\n",
    ")\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bad2fd22-8121-49a2-bf4c-ae23988d08d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt Version</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>JSON Validity Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt_V1_Batch</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prompt_V2_Batch</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prompt_V3_Batch</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prompt Version  Accuracy  JSON Validity Rate\n",
       "0  Prompt_V1_Batch       0.0                 0.0\n",
       "1  Prompt_V2_Batch       0.0                 0.0\n",
       "2  Prompt_V3_Batch       0.8                 1.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"Prompt Version\", \"Accuracy\", \"JSON Validity Rate\"]\n",
    ")\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e62a6a-f4fe-487e-9be8-25249ec2a316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
